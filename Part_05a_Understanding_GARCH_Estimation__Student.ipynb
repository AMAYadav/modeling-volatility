{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fintechsteve/modeling-volatility/blob/master/Part_04_Understanding_Turbulence_Signals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtCSSGGdu4Qt"
   },
   "source": [
    "# Part 05 (a): Understanding GARCH Estimation\n",
    "\n",
    "### In this section you will:\n",
    "\n",
    "\n",
    "*   Learn about GARCH estimation and its use in investment management\n",
    "*   Fit a GARCH Model to currency data\n",
    "*   Use a GARCH Model forecast volatility\n",
    "\n",
    "\n",
    "### Intro\n",
    "\n",
    "GARCH (Generalized Autoregressive Conditional Heteroskedastic) Estimation is used to model the variance of a time series.  Applied to investment management, a GARCH model can be used to model, and therefore predict, asset volatility.  Such models were proposed in \"[Generalized Autoregressive Conditional Heteroskedasticity](https://doi.org/10.1016/0304-4076%2886%2990063-1)\"\n",
    "\n",
    "Before we define a GARCH model, consider first an ARCH (Autoregressive Conditional Heteroskedastic) model.  This model assumes that the variance at time $t$ ($\\sigma^2_t$) depends linearly on the error $\\epsilon_t$,  at a fixed number ($q$) of previous time periods.  When ${q = 1}$ and assuming that the time series ${r_t}$  is stationary with constant mean ${\\mu}$ we have the ARCH(1) model:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "   r_t    & = & \\mu + \\epsilon_t \\\\\n",
    "   \\epsilon_t & = & \\sigma_t e_t \\\\\n",
    "   \\sigma^2_t & = & \\omega + \\alpha \\epsilon_{t-1}^2\n",
    "\\end{eqnarray*}\n",
    "\n",
    "More generally for ${q > 1}$ we have ARCH(q):\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "   \\sigma^2_t & = & \\omega + \\sum_{i=1}^{q}\\alpha_i \\epsilon_{t-i}^2 \n",
    "\\end{eqnarray*}\n",
    "\n",
    "The ARCH model captures the idea that the volatility of the series may change through time.  For example, a financial market may exhibit a period of low volatility followed by a period of high volatility. A time series that exhibits periods with increased (or decreased) volatility is called conditional heteroskedastic. \n",
    "\n",
    "The ARCH model may be extended to a GARCH model by adding linear dependence on a fixed number ($p$) of past variances.  For ${p = 1}$  and ${q = 1}$ the GARCH(1,1) model is\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "   r_t    & = & \\mu + \\epsilon_t \\\\\n",
    "   \\epsilon_t & = & \\sigma_t e_t \\\\\n",
    "   \\sigma^2_t & = & \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma^2_{t-1}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "More generally for ${p > 1}$ and ${q > 1}$ we have GARCH(p,q):\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "   \\sigma^2_t & = & \\omega + \\sum_{i=1}^{q}\\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^{p}\\beta_j \\sigma^2_{t-j}\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETMoGdnNrtjj"
   },
   "source": [
    "## Import all necessary libraries\n",
    "\n",
    "For this piece, we will need the following packages to be available to our environment:\n",
    "\n",
    "*   Pickle (For loading the data)\n",
    "*   Numpy and Pandas (For data manipulation)\n",
    "*   Arch (For GARCH estimation)\n",
    "*   Matplotlib and Seaborn(For time series visualization)\n",
    "\n",
    "If the packages are not available, install the with \"pip install X\" or \"conda install -c bashtage arch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FS6GYKq6T-ih"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import pickle\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBoMCDKYsdli"
   },
   "source": [
    "### Read in data from previously stored returns.pkl file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "id": "cFySsoztT-i9",
    "outputId": "8495eefc-671e-4942-a0ee-56543c378082",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./returns.pkl', 'rb') as f:\n",
    "    returns = pickle.load(f)\n",
    "    f.close()\n",
    "returns.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N20M0VTMyxil"
   },
   "source": [
    "### Calculate DXY Index\n",
    "\n",
    "In this part we scale the DXY Index to avoid numerical instabilities in the model fitting that may arise for inputs near zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naWuvBdzu-NZ"
   },
   "outputs": [],
   "source": [
    "dxy_weight = [0, 0.119, 0.036, 0, 0.136, 0.576, 0, 0, 0.091]\n",
    "dxy = returns.dot(dxy_weight)\n",
    "scaled_dxy = 10000*dxy\n",
    "scaled_dxy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byOlnZO40EDx"
   },
   "source": [
    "### Estimate a GARCH(1,1) model for the DXY Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "stRMHt7qy6Pr",
    "outputId": "d3feb0f9-2659-4159-f484-7706411d3029"
   },
   "outputs": [],
   "source": [
    "am = arch_model(scaled_dxy, mean = 'Constant', vol='GARCH', p=1, q=1)\n",
    "res = am.fit(update_freq=5)\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model corresponds to ${\\alpha  = .0422}$,  ${\\beta = .9552}$, ${\\omega = 9.5954e-04}$ and ${\\mu = 1.8657e-03}$ in the frame work described above\n",
    "\n",
    "\\begin{eqnarray}\n",
    "   r_t    & = & \\mu + \\epsilon_t \\\\\n",
    "   \\epsilon_t & = & \\sigma_t e_t \\\\\n",
    "   \\sigma^2_t & = & \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma^2_{t-1}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast volatility for the DXY Index\n",
    "\n",
    "Now we can use this model to forecast the future variance (volatility)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "-93ZyVJIPwv6",
    "outputId": "2c18930d-c218-480e-e971-25f8ab0bfc92"
   },
   "outputs": [],
   "source": [
    "forecasts = res.forecast(horizon = 1)\n",
    "print(forecasts.variance.index[-1])\n",
    "print(forecasts.variance.values[-1, -1]/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use a rolling window to forecast the one day volatility.  For each day we use the prior 260 days to fit a GARCH model and forecast a one day horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = 100\n",
    "lookback_window = 260\n",
    "horizon = 1\n",
    "f = []\n",
    "for i in range(1,n_days+1):\n",
    "    am = arch_model(scaled_dxy[-i-lookback_window:-i], mean = 'Constant', vol='GARCH', p=1, q=1)\n",
    "    res = am.fit(disp='off')\n",
    "    forecasts = res.forecast(horizon = horizon)\n",
    "    f.append({'var': forecasts.variance.iloc[-1, -1]/10000, 'date':forecasts.variance.index[-1]})\n",
    "    \n",
    "df_vol_pred = pd.DataFrame(f[::-1])\n",
    "df_vol_pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='date',y='var',data=df_vol_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can compare with daily volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy_sq = (dxy**2)\n",
    "plt.plot(dxy_sq.values[-n_days:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute a rolling one day volatility forecast for the entire period.  We compute forcasts for ${p}$ = 1, 2, and 3 and ${q}$ = 1, 2, and 3.  Note: this step is time consuming.  You may wish to load presaved data rather than running it live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days = dxy.size-260\n",
    "lookback_window = 260\n",
    "horizon = 1\n",
    "f = []\n",
    "for p in range(1,4):\n",
    "    for q in range(1,4):\n",
    "        for i in range(n_days+1, 1, -1):\n",
    "            am = arch_model(scaled_dxy[-i-lookback_window:-i], mean = 'Constant', vol='GARCH', p=p, q=q)\n",
    "            res = am.fit(disp='off')\n",
    "            forecasts = res.forecast(horizon = horizon)\n",
    "            f.append({'var': forecasts.variance.iloc[-1, -1]/10000, 'date':forecasts.variance.index[-1], 'p':p, 'q':q})\n",
    "            \n",
    "df_vol_pred = pd.DataFrame(f)\n",
    "df_vol_pred.to_pickle('./vol_pred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Part_??_Understanding_GARCH_Estimation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
