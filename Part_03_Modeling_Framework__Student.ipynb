{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fintechsteve/modeling-volatility/blob/master/Part_03_Modeling_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtCSSGGdu4Qt"
   },
   "source": [
    "## Part 03: Building a Modeling Framework\n",
    "\n",
    "### In this section you will:\n",
    "\n",
    "\n",
    "*   Understand the importance of creating holdback samples\n",
    "*   Explore some of the challenges of setting up a performance metric for data science models in a backtesting framework.\n",
    "*   Create a generalized function that can be used to provide in- and out-of-sample performance metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETMoGdnNrtjj"
   },
   "source": [
    "## Import all necessary libraries\n",
    "\n",
    "For this piece, we will need the following packages to be available to our environment:\n",
    "\n",
    "*   Numpy and Pandas (For data manipulation)\n",
    "*   DateTime (For basic date manipulation)\n",
    "*   Matplotlib (For timeseries vizualization)\n",
    "\n",
    "If the packages are not available, install the with \"pip install X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FS6GYKq6T-ih"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBoMCDKYsdli"
   },
   "source": [
    "### Read in data from previously stored returns.pkl file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "cFySsoztT-i9",
    "outputId": "094f5627-887d-485e-ca50-31e0951c81a7"
   },
   "outputs": [],
   "source": [
    "with open('./returns.pkl', 'rb') as f:\n",
    "    returns = pickle.load(f)\n",
    "    f.close()\n",
    "returns.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPfZk0NLtIaU"
   },
   "source": [
    "### The importance of creating a holdback sample\n",
    "\n",
    "When conducting data science around model building, it is important to understand the role that time plays in your modeling.\n",
    "\n",
    "All estimation must be done using historical data. Inferences that arise from \"forward looking\" data can bias our understanding and the model decision making process, so it is important that we exclude them from calculations.\n",
    "\n",
    "Unfortunately, we are not always clear about the ways in which \"forward looking\" can enter our modeling process and some disciplines are notoriously lax in their approach. The following \"forward looking\" data should be carefully controlled:\n",
    "\n",
    "1.   Back-casting signals and model weights over the period used for estimation (in-sample). While the performance in this sample can be a useful gut check, it is dangerous to place too much weight on these insights.\n",
    "\n",
    "2.   Data alignment and computational lag. If you run a model using data that goes through 5pm ET on a particular day, you probably can't implement a signal based on this until close of business the following day. If the data takes longer to reach your system (e.g. arrives with a 1 day processing lag) your effective lag may be longer. Performance between the date the model data is labeled and the earliest date a trade could be implemented should not be included in out-of-sample performance.\n",
    "\n",
    "3.   Data used for macro-parameter or hyper-parameter settings. This is where most financial data scientists get themselves into trouble. If you change the parameters for an estimation window or maximum number of lags in a model using some kind of objective critereon (be it error related, e.g. RMSE, AIC or performance related, e.g. mean return, sharpe ratio, information ratio), you cannot truly count the performance over the period used to make this decision as in-sample.\n",
    "\n",
    "   This becomes particularly problematic if you use the entire sample to reparameterize your model (e.g. because you found that the original parameterization did not work).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Wdhf13bTZHw"
   },
   "source": [
    "## Best practice for backtesting\n",
    "\n",
    "Proper discipline around backtesting is critical and difficult to do right. At a minimum you should:\n",
    "\n",
    "* Create a holdback period and only look at performance during this period once you are confident you have finished changing parameters on your model.\n",
    "* Determine the method of evaluating your model and what you will do if your out-of-sample performance fails to meet the in-sample performance.\n",
    "* Parameterize your model using a subset of the non holdback period of data. Ideally use cross-validation methods to minimize overfitting.\n",
    "\n",
    "Ideally you should also test your model on different out of sample periods, subsamples of securities, etc to determine the robustness of your solution. However, there is an art to doing this in such a way that your testing does not influence or induce further model tweaking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TrOHQab8WKtX"
   },
   "source": [
    "## Creating a generic model and testing framework\n",
    "\n",
    "To help us understand our testing framework, lets create a generic model and a separate function that allows us to evaluate the performance of a model.\n",
    "\n",
    "We can think of a model as a function that takes in a set of input data, a set of parameters and produces a set of model weights.\n",
    "\n",
    "In the case of this example, the model weights represent be the fraction of exposure we maintain to the DXY basket (vs simply remaining hedged in our base USD currency).\n",
    "\n",
    "Input data are the currency returns matrix. And finally parameters include:\n",
    "\n",
    "1) Model parameters such as lookback windows for averaging, lag structure for timeseries estimators (such as maximum number of lags on AR and MA processes).\n",
    "2) Hyperparameters, such as the window over which parameter estimation vs cross-validation is done, parameters for turning signals into weights, etc.\n",
    "3) Modeling framework parameters, such as the extent of the holdback parameter and any framework driven constraints on the output (e.g. rescaling out of sample weights to be forced to be uniformly distributed ex post).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgpMIQmXAivD"
   },
   "source": [
    "## A random model with a fixed seed\n",
    "\n",
    "To test our framework, let's create a model that generates random weights regardless of the input data and parameters.\n",
    "\n",
    "We will make the requirement that weights in-sample are uniformly distributed over [0,1] from a modeling framework perspective. However, it is easier (and better) to trust the model to do this, given our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "gmEZQCKjGAvi",
    "outputId": "25586b78-1673-4882-aed5-017efcc9ed26"
   },
   "outputs": [],
   "source": [
    "rets = returns\n",
    "framework_params = {'insample_start_date': '1975-01-02',\n",
    "                    'insample_end_date': '2000-01-01'}\n",
    "model_params = {'seed': 1}\n",
    "np.random.seed(seed=model_params['seed'])\n",
    "randwts = pd.DataFrame(np.random.rand(rets['AUD'].count(),1), index=rets.index)\n",
    "randwts_insample = randwts[framework_params['insample_start_date']:framework_params['insample_end_date']]\n",
    "randwts_insample = randwts_insample.rank()/randwts_insample.count()\n",
    "randwts[framework_params['insample_start_date']:framework_params['insample_end_date']] = randwts_insample\n",
    "randwts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qinK625FmwO3"
   },
   "outputs": [],
   "source": [
    "def random_model(rets, model_params, framework_params):\n",
    "  np.random.seed(seed=model_params['seed'])\n",
    "  randwts = pd.DataFrame(np.random.rand(rets['AUD'].count(),1), index=rets.index)\n",
    "  randwts_insample = randwts[framework_params['insample_start_date']:framework_params['insample_end_date']]\n",
    "  randwts_insample = randwts_insample.rank()/randwts_insample.count()\n",
    "  randwts[framework_params['insample_start_date']:framework_params['insample_end_date']] = randwts_insample\n",
    "  return randwts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "colab_type": "code",
    "id": "b7NGrGf0AhoE",
    "outputId": "63a68d26-2383-44aa-9e29-ad473df428d9"
   },
   "outputs": [],
   "source": [
    "framework_params = {'insample_start_date': '1975-01-02',\n",
    "                    'insample_end_date': '2000-01-01'}\n",
    "model_params = {'seed': 1}\n",
    "randwts = random_model(returns, model_params, framework_params)\n",
    "randwts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "VkhR2JNyeKpj",
    "outputId": "228df2e6-ba71-4b97-9a54-9ca838d71aec"
   },
   "outputs": [],
   "source": [
    "randwts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6rL7V05_kAzg"
   },
   "source": [
    "### Create an evaluation function that calculates the relationship between weight and subsequent DXY index volatility\n",
    "\n",
    "The measure we are interested in is the subsequent volatility of the dxy index. For the sake of argument, we will simply use squared returns to proxy volatility (Generally currencies shouldn't have a trend if implemented using forwards to avoid interest rate differentials).\n",
    "\n",
    "Start by calculating the dxy index again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "ZYRisZw66GDy",
    "outputId": "b536af5d-2ab3-4592-bc1b-a236f5a4c2ef"
   },
   "outputs": [],
   "source": [
    "dxy_weight = [0, 0.119, 0.036, 0, 0.136, 0.576, 0, 0, 0.091]\n",
    "dxy = pd.DataFrame(returns.dot(dxy_weight))\n",
    "dxy.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdLsnvvJKLkF"
   },
   "source": [
    "Now create forward looking squared returns. Note that we need to decide what horizon we measure volatility over. We assume here that it is an end of day decision to hedge volatility for the next day, so a 1 day forward lookahead rule is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "al1TiJa-msmW",
    "outputId": "8e51931f-9d15-4473-de83-8e2d962d2eae"
   },
   "outputs": [],
   "source": [
    "dxy_forward = dxy.shift(-1)\n",
    "dxy_forward_sq = dxy_forward**2\n",
    "dxy_forward_sq.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Og4Ir3L-Kvii"
   },
   "source": [
    "We need a function that measures the volatility of a strategy by multiplying our weights by the forward-looking squared returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "lX2SH9yqI1e7",
    "outputId": "32cac46a-18ef-405c-9499-86eeff580bd3"
   },
   "outputs": [],
   "source": [
    "model_vol = randwts*dxy_forward_sq\n",
    "model_vol.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrZTZ568uGXu"
   },
   "source": [
    "The problem with this is that a model biased towards zero has a lower volatility. We need a measure that takes into account the overall bias of the model and only gives credit for the ability to selectively identify periods of higher volatility. \n",
    "\n",
    "Note: Depending on what you are trying to measure, there is a choice to either demean over:\n",
    "a) just the in sample period.\n",
    "b) the whole sample.\n",
    "c) the in and out of sample periods separately.\n",
    "\n",
    "Method (b) risks introducing forward looking biases. Method (c) is appropriate if you believe that the performance out of sample will be systematically biased vs in sample. For the example below we use method (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCW0NX0odY_R"
   },
   "outputs": [],
   "source": [
    "def model_perf(model_wts, dxyfsq, framework_params):\n",
    "  model_vol = (model_wts)*dxyfsq\n",
    "  avgmodel_vol = np.mean(model_wts.loc[framework_params['insample_start_date']:framework_params['insample_end_date']])*dxyfsq\n",
    "  is_rmse = np.sqrt(np.mean(model_vol.loc[framework_params['insample_start_date']:framework_params['insample_end_date']]))[0]\n",
    "  out_rmse = np.sqrt(np.mean(model_vol.loc[framework_params['outofsample_start_date']:framework_params['outofsample_end_date']]))[0]\n",
    "\n",
    "  is_avg_rmse = np.sqrt(np.mean(avgmodel_vol.loc[framework_params['insample_start_date']:framework_params['insample_end_date']]))[0]\n",
    "  out_avg_rmse = np.sqrt(np.mean(avgmodel_vol.loc[framework_params['outofsample_start_date']:framework_params['outofsample_end_date']]))[0]\n",
    "\n",
    "  model_perf_stats = {'insample rmse': is_rmse, 'insample excess rmse': is_rmse - is_avg_rmse,\n",
    "                      'out-of-sample rmse': out_rmse, 'out-of-sample excess rmse': out_rmse - out_avg_rmse}\n",
    "  return model_perf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zqf9ivy6XYe4",
    "outputId": "90f384f7-fdcd-42e2-85b7-204585beee35"
   },
   "outputs": [],
   "source": [
    "rets = returns\n",
    "framework_params = {'insample_start_date': '1975-01-02',\n",
    "                    'insample_end_date': '2000-01-01',\n",
    "                    'outofsample_start_date': '2000-01-02',\n",
    "                    'outofsample_end_date': '2017-12-26'}\n",
    "model_perf_stats = model_perf(randwts, dxy_forward_sq, framework_params)\n",
    "model_perf_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2lwju84oWkG"
   },
   "source": [
    "### Exploring the properties of our performance statistics with 1,000 random models\n",
    "\n",
    "To better understand the statistics we have created, let's iterate over 1,000 random seeds and store the model performance statistics for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zcaj07aCaX6o"
   },
   "outputs": [],
   "source": [
    "framework_params = {'insample_start_date': '1975-01-02',\n",
    "                    'insample_end_date': '2000-01-01',\n",
    "                    'outofsample_start_date': '2000-01-02',\n",
    "                    'outofsample_end_date': '2017-12-26'}\n",
    "\n",
    "def random_models_by_seed(returns, framework_params, seed):\n",
    "  model_params = {'seed': seed}\n",
    "  randwts = random_model(returns, model_params, framework_params)\n",
    "  return model_perf(randwts, dxy_forward_sq, framework_params)\n",
    "\n",
    "rand_perf = pd.DataFrame(list(map(lambda x:random_models_by_seed(returns, framework_params, x), range(0,1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5bCh-IdiYaAT"
   },
   "source": [
    "We can plot the distribution of the performance statistics. We expect that the excess RMSE should be centered around zeros - which appears to be the case.\n",
    "\n",
    "Unsurprisingly, there is no evidence to suggest that a random model is able to predict volatility in or out of sample.\n",
    "\n",
    "However, performing tests like this are important. They help us confirm that parts of our modeling framework are working. Given the ease of introducing coding errors, it is **vital** to do tests of the code with noise to ensure that there is no leakage of information or misinterpretation of the results from a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "colab_type": "code",
    "id": "dMFhaNzNhe5l",
    "outputId": "e8232720-ac58-4f37-e96d-846d270691ec"
   },
   "outputs": [],
   "source": [
    "rand_perf.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "zMZuEE6YVNR8",
    "outputId": "3b22b285-abb0-4fe2-de89-68578c83deb5"
   },
   "outputs": [],
   "source": [
    "rand_perf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf460k2NX70c"
   },
   "outputs": [],
   "source": [
    "dxy_forward_sq.to_pickle('./dxy_forward_sq.pkl')\n",
    "dxy.to_pickle('./dxy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Part_03_Modeling_Framework.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:modeliing-volatility] *",
   "language": "python",
   "name": "conda-env-modeliing-volatility-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
